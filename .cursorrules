# ScopeX Mobile Automation Framework - Cursor Project Rules

## üéØ Project Overview
This is a comprehensive mobile automation framework using Maestro for testing the ScopeX mobile app on both Android and iOS platforms. The framework incorporates advanced Maestro features, detailed step execution, and scalable test management.

## üìÅ Project Structure
```
mobile-automation-scopex/
‚îú‚îÄ‚îÄ maestro.yaml                    # Main Maestro configuration
‚îú‚îÄ‚îÄ run-tests.sh                    # Advanced test runner script
‚îú‚îÄ‚îÄ setup.sh                        # Environment setup script
‚îú‚îÄ‚îÄ flows/                          # Test flows organized by category
‚îÇ   ‚îú‚îÄ‚îÄ smoke/                      # Quick smoke tests
‚îÇ   ‚îú‚îÄ‚îÄ regression/                 # Comprehensive regression tests
‚îÇ   ‚îú‚îÄ‚îÄ feature/                    # Feature-specific tests
‚îÇ   ‚îî‚îÄ‚îÄ integration/                # Integration tests
‚îú‚îÄ‚îÄ apps/                           # App binaries
‚îÇ   ‚îú‚îÄ‚îÄ android/app-release.apk
‚îÇ   ‚îî‚îÄ‚îÄ ios/MyApp.app
‚îî‚îÄ‚îÄ reports/                        # Test results and outputs
```

## üöÄ Framework Features
- Device management (Android/iOS)
- Tag-based test execution
- Comprehensive reporting (HTML, JUnit)
- AI analysis integration
- JavaScript integration for dynamic logic
- Flow hooks for setup/cleanup
- Conditional execution for platform-specific tests
- Advanced selectors for reliable element interaction

## üìù Coding Standards & Rules

### 1. Test Flow Organization
- **ALWAYS** organize test flows by category in the `flows/` directory
- **USE** descriptive tags for test categorization (smoke, regression, feature, integration)
- **FOLLOW** the naming convention: `category/test-name.yaml`
- **INCLUDE** proper metadata (appId, name, tags) in every flow

### 2. Maestro Flow Structure
```yaml
# Required metadata
appId: com.scopex.scopexmobilev2
name: "Descriptive Test Name"
tags: ["category", "specific-feature"]

# Environment variables
env:
  TEST_START_TIME: "${Date.now()}"
  PLATFORM: "${maestro.platform}"

# Flow hooks for setup/cleanup
onFlowStart:
  - evalScript: "console.log('Starting test...');"
  - evalScript: "output.startTime = Date.now();"

onFlowComplete:
  - evalScript: "console.log('Test completed');"
  - takeScreenshot: "test-complete"

---
# Test steps with detailed logging
- evalScript: "console.log('Step 1: Description...');"
- launchApp
- extendedWaitUntil:
    visible: "Element"
    timeout: 10000
```

### 3. Test Execution Commands
- **USE** the `run-tests.sh` script for all test execution
- **INCLUDE** appropriate tags for test selection
- **SPECIFY** platform when needed (`-p android` or `-p ios`)
- **ENABLE** AI analysis with `--analyze` for regression tests
- **USE** `--format junit` for CI/CD integration

### 4. Error Handling & Reliability
- **ALWAYS** use `extendedWaitUntil` instead of simple `assertVisible`
- **INCLUDE** proper timeout values (5000-15000ms)
- **IMPLEMENT** retry logic for flaky elements
- **USE** `scrollUntilVisible` for elements that might be off-screen
- **ADD** comprehensive logging with `evalScript`

### 5. Platform-Specific Considerations
- **USE** conditional execution for platform differences
- **TEST** on both Android and iOS when possible
- **CONSIDER** platform-specific element selectors
- **HANDLE** platform-specific behaviors (permissions, alerts, etc.)

### 6. Reporting & Documentation
- **GENERATE** both HTML and JUnit reports
- **INCLUDE** screenshots at key test points
- **RECORD** video for complex test flows
- **DOCUMENT** test purpose and expected behavior
- **MAINTAIN** the `.cursor` file with framework reference

## üîß Development Guidelines

### 1. Creating New Test Flows
1. **COPY** the template from `flows/template-flow.yaml`
2. **MODIFY** metadata (name, tags, description)
3. **ADD** appropriate flow hooks
4. **IMPLEMENT** detailed step logging
5. **INCLUDE** proper assertions and error handling
6. **TEST** on both platforms if applicable

### 2. Test Flow Best Practices
- **START** with smoke tests for basic functionality
- **BUILD** regression tests for comprehensive coverage
- **CREATE** feature tests for specific functionality
- **DEVELOP** integration tests for end-to-end scenarios
- **USE** descriptive step names and logging
- **INCLUDE** screenshots at key verification points

### 3. JavaScript Integration
- **USE** `evalScript` for dynamic logic and logging
- **EXTRACT** element text with `copyTextFrom`
- **MAKE** HTTP requests for API testing when needed
- **STORE** data in `output` object for cross-step usage
- **LOG** important information for debugging

### 4. Advanced Selectors
- **PREFER** text-based selectors for readability
- **USE** ID selectors when available and stable
- **INCLUDE** index for multiple matching elements
- **COMBINE** multiple selector types for reliability
- **AVOID** fragile selectors that change frequently

## üéØ Test Categories & Tags

### Smoke Tests
- **Purpose**: Quick validation of basic functionality
- **Tags**: `smoke`, `critical`
- **Examples**: App launch, basic navigation
- **Execution**: Run first, fast execution
- **Current Tests**: 
  - `flows/smoke/app-launch.yaml` (smoke, launch, critical)
  - `flows/feature/guest-user-journey.yaml` (smoke, regression, guest, onboarding, critical)

### Regression Tests
- **Purpose**: Comprehensive testing of existing features
- **Tags**: `regression`, `critical`
- **Examples**: Complete user journeys, end-to-end flows
- **Execution**: Run after smoke tests, comprehensive coverage
- **Current Tests**:
  - `flows/feature/guest-user-journey.yaml` (smoke, regression, guest, onboarding, critical)

### Feature Tests (`flows/feature/`)
- **Purpose**: Testing specific features
- **Tags**: `feature`, `template`, `example`
- **Examples**: User authentication, payment flows
- **Execution**: Run for specific feature validation
- **Current Tests**:
  - `flows/feature/guest-user-journey.yaml` (smoke, regression, guest, onboarding, critical)
  - `flows/feature/template-flow.yaml` (template, example)

### Integration Tests (`flows/integration/`)
- **Purpose**: Testing component integration
- **Tags**: `integration`, `navigation`, `critical`
- **Examples**: Cross-feature navigation, API integration
- **Execution**: Run for integration validation
- **Current Tests**:
  - `flows/integration/main-navigation.yaml` (integration, navigation, critical)

## üöÄ Command Examples

### Device Management
```bash
./run-tests.sh --start-device android
./run-tests.sh --start-device ios
./run-tests.sh --list-devices
```

### Test Execution
```bash
./run-tests.sh -t smoke                    # Smoke tests
./run-tests.sh -t regression --analyze     # Regression with AI
./run-tests.sh -p android -t critical      # Critical tests on Android
./run-tests.sh --format junit -t smoke     # JUnit reports
./run-tests.sh -v --debug --timeout 300    # Verbose debug
```

### Advanced Features
```bash
./run-tests.sh --sequential --retry 3      # Sequential with retries
./run-tests.sh --device "emulator-5554"    # Specific device
./run-tests.sh -t "smoke,critical"         # Multiple tags
```

## üîç Troubleshooting Rules

### Common Issues
1. **Element not found**: Use `scrollUntilVisible` or `extendedWaitUntil`
2. **Test flakiness**: Add proper waits and retry logic
3. **Platform differences**: Use conditional execution
4. **Device issues**: Check device connectivity and restart if needed

### Debug Commands
```bash
./run-tests.sh -v --debug                  # Verbose output
./run-tests.sh --list-devices              # Check devices
./run-tests.sh --start-device android      # Start fresh device
./run-tests.sh --timeout 300 --retry 3     # Timeout and retries
```

## üìä Reporting Standards

### HTML Reports
- Interactive test results with step-by-step timeline
- Embedded screenshots and video recordings
- Performance metrics and execution statistics
- Error details with context and debugging info

### JUnit Reports
- CI/CD integration ready
- Test result aggregation for trend analysis
- Failure analysis with detailed error reporting

### AI Analysis
- Automated issue detection in UI/UX
- Internationalization checks for localization
- Performance insights and optimization suggestions

## üéØ Quality Assurance

### Code Review Checklist
- [ ] Proper test organization and categorization
- [ ] Comprehensive logging and error handling
- [ ] Platform-specific considerations
- [ ] Appropriate use of advanced selectors
- [ ] Proper timeout and retry logic
- [ ] Clear test documentation and purpose
- [ ] Screenshots at key verification points

### Performance Standards
- Smoke tests should complete within 2-3 minutes
- Regression tests should complete within 10-15 minutes
- Feature tests should complete within 5-8 minutes
- Integration tests should complete within 8-12 minutes

## üîÑ CI/CD Integration

### GitHub Actions Example
```yaml
name: Maestro Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: macos-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run Smoke Tests
        run: |
          ./run-tests.sh -p android -t smoke --format junit
          ./run-tests.sh -p ios -t smoke --format junit
      - name: Run Regression Tests
        run: |
          ./run-tests.sh -p android -t regression --format junit
```

## üìö Documentation Requirements

### Required Files
- `README.md` - Complete framework guide
- `.cursor` - Comprehensive Maestro reference
- `maestro.yaml` - Configuration examples
- Test flows - Advanced feature demonstrations

### Documentation Standards
- Clear and concise descriptions
- Code examples for all features
- Troubleshooting guides
- Best practices and guidelines
- Links to official documentation

## üÜò Support & Resources

### Framework Documentation
- `.cursor` file - Comprehensive Maestro reference guide
- `maestro.yaml` - Configuration examples and best practices
- Test flows - Advanced feature demonstrations

### External Resources
- **Maestro Documentation**: https://docs.maestro.dev/
- **MCP Integration**: https://docs.maestro.dev/getting-started/maestro-mcp
- **Best Practices**: https://maestro.dev/blog/maestro-best-practices-structuring-your-test-suite
- **Community**: https://github.com/mobile-dev-inc/maestro

---

**Framework Version**: 2.0  
**Last Updated**: August 2025  
**Status**: ‚úÖ Production Ready with Advanced Features

*Follow these rules to maintain code quality, consistency, and reliability across the ScopeX Mobile Automation Framework.*
